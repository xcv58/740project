* Hadoop 2.2.0
   1. Install Java 1.7
   2. Setup SSH login by dsa key
   3. Download the Hadoop 2.2.0
   4. Setup the Hadoop Environment Variables in Bash/zsh
      Paste lines blow in your .zshrc file or other shell you used.
         export HADOOP_INSTALL=/Users/xcv58/hadoop
         export HADOOP_HOME=$HADOOP_INSTALL
         export PATH=$PATH:$HADOOP_INSTALL/bin:$HADOOP_INSTALL/sbin
         export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
         export HADOOP_COMMON_HOME=$HADOOP_INSTALL
         export HADOOP_HDFS_HOME=$HADOOP_INSTALL
         export YARN_HOME=$HADOOP_INSTALL
   5. Configure Hadoop
        $ cd /usr/local/hadoop/etc/hadoop
        $ vi core-site.xml
        #Paste following between <configuration>
         
        <property>
           <name>fs.default.name</name>
           <value>hdfs://localhost:9000</value>
        </property>
         
         
        $ vi yarn-site.xml
        #Paste following between <configuration>
         
        <property>
           <name>yarn.nodemanager.aux-services</name>
           <value>mapreduce_shuffle</value>
        </property>
        <property>
           <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
           <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
         
         
        $ mv mapred-site.xml.template mapred-site.xml
        $ vi mapred-site.xml
        #Paste following between <configuration>
         
        <property>
           <name>mapreduce.framework.name</name>
           <value>yarn</value>
        </property>

				You can assign more memory be editing the conf/mapred-site.xml file and adding the property:

				<property>
				<name>mapred.child.java.opts</name>
				<value>-Xmx1024m</value>
				</property>
         
        $ cd ~
        $ mkdir -p mydata/hdfs/namenode
        $ mkdir -p mydata/hdfs/datanode
        $ cd /usr/local/hadoop/etc/hadoop
        $ vi hdfs-site.xml
        Paste following between <configuration> tag
         
        <property>
           <name>dfs.replication</name>
           <value>1</value>
         </property>
         <property>
           <name>dfs.namenode.name.dir</name>
           <value>file:/home/hduser/mydata/hdfs/namenode</value>
         </property>
         <property>
           <name>dfs.datanode.data.dir</name>
           <value>file:/home/hduser/mydata/hdfs/datanode</value>
         </property>
	 
   1. Format Namenode
        hdfs namenode -format
   2. Start Hadoop Service
      start-dfs.sh
      ....
      start-yarn.sh
      ....
      hduser@ubuntu40:~$ jps
      If everything is sucessful, you should see following services running
      2583 DataNode
      2970 ResourceManager
      3461 Jps
      3177 NodeManager
      2361 NameNode
      2840 SecondaryNameNode
   3. Run Hadoop Example
      hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar pi 2 5
      Number of Maps = 2
      Samples per Map = 5
      13/10/21 18:41:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
      Wrote input for Map #0
      Wrote input for Map #1
      Starting Job
      13/10/21 18:41:04 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
      13/10/21 18:41:04 INFO input.FileInputFormat: Total input paths to process : 2
      13/10/21 18:41:04 INFO mapreduce.JobSubmitter: number of splits:2
      13/10/21 18:41:04 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
      ...

** This Turtorial Url: 
   [[http://codesfusion.blogspot.com/2013/10/setup-hadoop-2x-220-on-ubuntu.html]]
   
* Compile Your example
  javac -classpath $HADOOP_INSTALL/share/hadoop/common/hadoop-common-2.2.0.jar:$HADOOP_INSTALL/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.2.0.jar:$HADOOP_INSTALL/share/hadoop/common/lib/commons-cli-1.2.jar -d wordcount_classes WordCount.java

* JAR the .class file
